{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Webscraping_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4tqSZM0IJaHglEJiFjcM5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enyeneraph/Python-Jobs-Analysis/blob/main/Webscraping_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UiVc29L0m2h"
      },
      "source": [
        "Importing the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scPwnLJz0D7_"
      },
      "source": [
        "import requests\n",
        "from html.parser import HTMLParser\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_DqaQx9nmbF"
      },
      "source": [
        "def a_href(word,tag, attrs, tag_check = 'a'):\n",
        "  if tag == tag_check:\n",
        "    for i in attrs:\n",
        "      x = re.search(str(('href', word)), str(i))\n",
        "      if x:\n",
        "        return x.groups()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVfdjrQfg8yf"
      },
      "source": [
        "\n",
        "class JobDetailsParser(HTMLParser):\n",
        "  \n",
        "  ''' This class extracts details such as job title, company name, \n",
        "  location, category, date posted as well as job description from \n",
        "  each page opened. '''\n",
        "\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.ress = list()\n",
        "    self.job_title = False\n",
        "    self.category = False\n",
        "    self.location = False\n",
        "    self.req = False\n",
        "    self.date = False\n",
        "    self.h2 = False\n",
        "    self.company_details = False\n",
        "    self.company_name = False\n",
        "    self.handle_req = False\n",
        "    self.job_type = False\n",
        "    self.req_str = \"\"\n",
        "    self.type_str = \"\"\n",
        "    super().__init__()\n",
        "  \n",
        "  def handle_starttag(self, tag, attrs):\n",
        "\n",
        "    #job title: parent + sibling tag\n",
        "    if (tag == 'span' and ('class', 'listing-company-name') in attrs): #parent tag\n",
        "      self.company_details = True \n",
        "      self.job_title = True\n",
        "    elif tag == 'span' and ('class', 'listing-new') in attrs: #sibling tag\n",
        "      self.job_title = False\n",
        "    #job location: parent tag\n",
        "    elif (tag == 'span' and ('class', 'listing-location') in  attrs): \n",
        "      self.location = True  \n",
        "    #job category: parent tag\n",
        "    elif tag == 'span' and ('class', 'listing-company-category') in attrs:\n",
        "      self.category = True\n",
        "    #requirements\n",
        "    elif tag == 'h2':\n",
        "      self.h2 = True\n",
        "    #type\n",
        "    elif tag == 'span' and ('class', 'listing-job-type') in attrs:\n",
        "      self.job_type = True\n",
        "    #date\n",
        "    self.date = tag == 'time'\n",
        "  \n",
        "  def handle_endtag(self, tag):\n",
        "    #jobtitle\n",
        "    if self.job_title and tag == 'span':\n",
        "      self.job_title = False\n",
        "    #location\n",
        "    elif self.location:\n",
        "      self.location = False\n",
        "    #category\n",
        "    elif self.category:\n",
        "      self.category = False\n",
        "    #date\n",
        "    elif self.date:\n",
        "      self.date = False\n",
        "    #type\n",
        "    elif self.job_type and tag == 'span':\n",
        "      self.job_type = False\n",
        "    #company_name\n",
        "    elif tag == 'br' and self.company_details:\n",
        "      self.company_name = True\n",
        "    elif tag == 'span' and self.company_name:\n",
        "      self.company_name, self.company_details = False, False\n",
        "    #requirements\n",
        "    elif self.req and tag in ['ul', 'ol', 'dl']:\n",
        "      self.req = False\n",
        " \n",
        "  \n",
        "  def handle_data(self,data):\n",
        "    #job title\n",
        "    if self.job_title and data.strip() != '':\n",
        "      self.ress.append(data.strip())\n",
        "    #location\n",
        "    elif self.location and data.strip() != '':\n",
        "      self.ress.append(data.strip())\n",
        "    #category\n",
        "    elif self.category and data.strip() != '':\n",
        "      self.ress.append(data.strip())\n",
        "      self.ress.append(self.type_str) \n",
        "      self.ress.append(self.req_str) #to keep requirements which is text heavy as the last item\n",
        "\n",
        "    #date\n",
        "    elif self.date and data.strip() != '':\n",
        "      self.ress.append(data.strip())\n",
        "    #type\n",
        "    elif self.job_type and data.strip() not in ('', ):\n",
        "      self.type_str += data.strip() #joining all data from types together to make a string \n",
        "\n",
        "    # #company_name\n",
        "    elif self.company_name and data.strip() != '':\n",
        "      self.ress.append(data.strip())\n",
        "    #requirements\n",
        "    elif self.h2 and data.strip() == 'Requirements':\n",
        "      self.req = True\n",
        "    elif self.req and data.strip() != '':\n",
        "      self.req_str += data.strip() + ' '\n",
        "\n",
        "  def return_ress(self):\n",
        "    return self.ress "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFzc__j1lmOP"
      },
      "source": [
        "class JobListParser(HTMLParser):\n",
        "\n",
        "  '''This extracts links to each job, opens the links and extracts the data as described in the JobDetailsParser class '''\n",
        "\n",
        "  list_of_list = []\n",
        "  def __init__(self):\n",
        "    self.data_handler = False\n",
        "    self.ol_handle = False\n",
        "    self.next_page = False\n",
        "    super().__init__()\n",
        "\n",
        "  def handle_starttag(self, tag, attrs):\n",
        "    if tag == 'ol' and ('class', 'list-recent-jobs list-row-container menu') in attrs:\n",
        "      self.ol_handle = True\n",
        "    elif a_href('/jobs/[0-9]+/', tag, attrs) and self.ol_handle:\n",
        "      self.data_handler = True\n",
        "      job_url = 'https://www.python.org' + a_href('/jobs/[0-9]+/', tag, attrs)[0].split()[1].strip(\"'\")\n",
        "      self.parse_url(job_url, JobDetailsParser())\n",
        "\n",
        "    elif tag == 'li' and ('class', 'next') in attrs:\n",
        "      self.next_page  = True\n",
        "    elif self.next_page and tag == 'a':\n",
        "      next_page_url = 'https://www.python.org/jobs/' + attrs[0][1]\n",
        "      self.next_page = False\n",
        "      if next_page_url != 'https://www.python.org/jobs/disabled':\n",
        "        self.parse_url(next_page_url, JobListParser())\n",
        "\n",
        "\n",
        "  def parse_url(self, job_url, parser):\n",
        "      self.text_ = requests.get(job_url).text\n",
        "      self.parser_ = parser\n",
        "      self.parser_.feed(self.text_)\n",
        "      if hasattr(parser, 'ress'):\n",
        "        self.list_of_list.append(self.parser_.ress)\n",
        "\n",
        "\n",
        "  \n",
        "  def handle_endtag(self, tag):\n",
        "    if tag == 'a' and self.data_handler:\n",
        "      self.data_handler = False\n",
        "    elif tag == 'ol' and self.ol_handle:\n",
        "      self.ol_handle = False\n",
        "  \n",
        "  def return_list(self):\n",
        "    return self.list_of_list\n",
        "      \n",
        "  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX2enM8wlU26"
      },
      "source": [
        "text = requests.get('https://www.python.org/jobs/').text"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5WwJT4CrpY_",
        "outputId": "33c8cebe-84fb-490c-dc20-47eec8d3aaa1"
      },
      "source": [
        "#this operation should be run only once.\n",
        "parser = JobListParser()\n",
        "parser.feed(text)\n",
        "lists_ = parser.list_of_list\n",
        "len(lists_)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKLlFzpzqq0o"
      },
      "source": [
        "#converting the lists of jobs and their descriptions  to a dataframe\n",
        "import pandas as pd\n",
        "columns = ('Job_Title', 'Company', 'Location', 'Date_Posted', 'Category', 'Looking_for', 'Description')\n",
        "df = pd.DataFrame(lists_, columns=columns)\n",
        " "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "qDrw7W7JBYpo",
        "outputId": "8828de3a-a176-41a2-e40a-59fd9fdb4074"
      },
      "source": [
        "#\n",
        "from google.colab import files\n",
        "df.to_csv('pythonjobs.csv', index=False) \n",
        "files.download('pythonjobs.csv')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4ec86907-0750-4e6d-bd74-24fc4cb2f9c5\", \"pythonjobs.csv\", 110052)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW8HwLBbl3E6"
      },
      "source": [
        ""
      ]
    }
  ]
}